---
title: "README for Getting and Cleaning Data Course Project"
author: "Juanhe Tan"
date: "2 December 2018"
output: html_document
---

This repo contains:

1. A script called run_analysis.R that takes the UCI Human Activity Recognition 
Using Smartphones (UCI HAR) Data Set from [here](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)
and generates a tidy data set reflecting the average of mean and standard 
deviation variables for each subject and activity.
2. A tidy data set called result.txt that is the product of the script in (1).
3. A codebook called CodeBook.md that describes each of the variables in (2).

## run_analysis.R

This script uses the "data.table" package.

The script should be with the working directory set to be the folder containing 
the UCI HAR dataset's "README", "activity_labels", "features", and "features_info"
files, as well as the "test" and "train" folders i.e. the "UCI HAR Dataset"
folder that can be downlowded from [here](http://archive.ics.uci.edu/ml/machine-learning-databases/00240/) 
or [here](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip).  

For more information on the underlying data, please refer to the README file in
the "UCI HAR Dataset" folder.

The script run_analysis.R has five parts:  

1. **Creates one data frame each for the training and test sets.**
This part of the script:
    * Extracts the measurement data for the test set from the "test" folder
    ("test/X_test.txt").
    * Cleans the data by:
        + Splitting individual data entries using a single space as a separator;
        + Removing empty entries that result from the splitting;
        + Converting the data into numeric data;
        + Reshaping the data into a data frame with 561 columns, one for each 
        measurement feature.
    * Extracts the subject ("test/subject_test.txt") and activity
    ("test/y_test.txt") data for the test set from the "test" folder.
    * Merges the subject, activity, and measurement data for the test set into a
    single data frame called "test_data" with 563 columns.
    * Repeats the above steps for the training set from the "train" folder,
    creating a data frame called "train_data" with 563 columns.
    
2. **Merges "test_data" and "train_data"** from Step 1 into one data frame
called "dataset" with 563 columns.
    * Also clears data and values that are no longer required from the global
    environment, to save space.
    
3. **Extracts from "dataset" only those columns that relate to the mean
(denoted by "mean()" in the UCI HAR data set) or standard deviation ("std()") of
measurements.**
    * To do this, the script uses the "grep" function to identify which of the
    561 columns with variables has "mean()" or "std()" in their names. There are
    66 such variables.
    * Note that this does _not_ include the mean frequency ("meanFreq()")
    variables.
    
4. **Labels the data with descriptive names.** This part of the script:
    * Changes the activity labels from numbers 1-6 to descriptive labels from
    the "activity_labels" file in the UCI HAR Dataset folder. All labels are
    turned into lower case and digits, spaces and underscores are removed.
    * Changes the label of each variable into more descriptive ones, by:
        + Changing everything into lowercase;
        + Spelling out abbreviations (e.g. "t" becomes "timesignal", "acc" 
        becomes "accelerometer", "x" becomes "xdimension", etc.);
        + Removing unwanted characters like hyphens, digits, brackets, spaces.
    
5. **Creates a second, independent tidy data set that reflects the average for
each variable for each pair of (subject, activity).** This part of the script:
    * Breaks "dataset" into different parts for each pair of (subject, activity)
    and calculates the average of each of the 66 variables, using data.table
    functionality. Since there are 30 subjects and 6 activities, there are 180
    pairs in total.
    * Relabels the variable names with the word "average" in front to reflect
    that averages have been calculated.
    * Writes the new data set into a .txt file called "result.txt", with
    row.names = FALSE.
    * Removes all data and values from the global environment to save space.

## result.txt

This is the tidy data set that is generated by run_analysis.R. It has 181 rows
(including the header row) and 68 columns (comprising one for the subject, one
for the activity, and one for each of 66 "mean()" and "std()" variables). For
more details, refer to CodeBook.md in this repo.

## CodeBook.md

This code book explains what the different variables of result.txt are and how
they were derived.